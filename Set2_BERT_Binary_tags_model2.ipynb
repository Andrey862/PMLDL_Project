{"nbformat":4,"nbformat_minor":4,"metadata":{"notebookPath":"Set2_BERT_Binary_tags_model2.ipynb","language_info":{"mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py","version":"3.7.7","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python"},"notebookId":"ce8a5ac9-d01d-4c14-8d60-42a8eb86e188","kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"ydsNotebookPath":"Thesis_BERT_Binary-Context.ipynb"},"cells":[{"cell_type":"code","source":"#!g1.1\n!git clone https://github.com/nerel-ds/NEREL","metadata":{"outputId":"2f60b594-2d3f-407b-8b11-6639cd00d2aa","id":"8vRu5JKz1ir8","cellId":"c8aacc5a-0610-479b-af39-c936bb1ff95a","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!unzip NEREL-v1.0.zip -d NEREL","metadata":{"scrolled":true,"cellId":"1ty6mfv872tle06tj03k2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\n## Read the data# Reading files\nfrom collections import namedtuple\nimport re\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport nltk\n\nAnn = namedtuple('annotation', ['tag', 'start1', 'end1', 'start2', 'end2', 'text'])\nRel = namedtuple('relationship', ['tag', 'arg1', 'arg2'])\n\ndef read_files(folder):\n    filenames = sorted(set(e[:e.rfind('.')] for e in os.listdir(folder)))[1:]\n    \n    texts, entities, relationships  = [], [], []\n    for file in tqdm(filenames):\n       # if (not file): continue\n        path1 = os.path.join(folder, file+'.txt')\n        path2 = os.path.join(folder, file+'.ann')\n        if (not os.path.exists(path2)):\n            print(f'{path2} not found')\n            continue\n            #with open(path2, 'w'):\n            #    pass\n            \n        with open(path1, 'r', encoding=\"utf8\") as text, open(path2, 'r', encoding=\"utf8\") as ann:\n            texts.append(text.read())\n\n            file_entities = {}\n            file_relationship = []\n            regex_ent = r'T(?P<id>\\d+)\\s(?P<tag>\\w+)\\s(?P<start1>\\d+) (?P<end1>\\d+)(;(?P<start2>\\d+) (?P<end2>\\d+))?\\s(?P<text>.*)'\n            regex_rel = r'R(?P<id>\\d+)\\s(?P<tag>\\w+)\\sArg1:T(?P<arg1>\\d+) Arg2:T(?P<arg2>\\d+)'\n            \n            \n            for row in sorted(ann.readlines(), reverse=True):\n                #print(row)\n                match_ent = re.match(regex_ent, row)\n                match_rel = re.match(regex_rel, row)\n                if (match_ent):\n                    res = match_ent.groupdict()\n                    res['start1'] = int(res['start1'])\n                    res['end1'] = int(res['end1'])\n                    if (res['start2'] is not None):\n                        res['start2'] = int(res['start2'])\n                        res['end2'] = int(res['end2'])\n                    id = res.pop('id')\n                    file_entities[id] = Ann(**res)\n                elif (match_rel):\n                    try:\n                        res = match_rel.groupdict()\n                        res['arg1'] = file_entities[res['arg1']]\n                        res['arg2'] = file_entities[res['arg2']]\n                        id = res.pop('id')\n                        file_relationship.append(Rel(**res))\n                    except KeyError as e:\n                        print(f'not found T{e} row={row}')\n                else:\n                    print(f'incorrect format in: row={row} file={file}')\n            entities.append(file_entities)\n            relationships.append(file_relationship)\n    entities = [sorted(e.values(), key = lambda x: (x.start1, x.end1)) for e in entities]\n    return texts, entities, relationships, filenames","metadata":{"id":"i0hrNfhb17mT","cellId":"eb41719b-969a-42ca-b86b-a342cdba7d47","trusted":true},"outputs":[],"execution_count":325},{"cell_type":"code","source":"#!g1.1\nfolder = 'NEREL/NEREL-v1.0/train'\ntexts, entities, relationships, filenames = read_files(folder)","metadata":{"outputId":"af7aafa1-8ff4-4710-dc53-25c63fcb19bf","id":"R8DaAwoP18sY","cellId":"fa765711-be27-4ead-adbe-3a89b50071d6","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":" 56%|█████▌    | 415/745 [00:01<00:01, 290.97it/s]"},{"output_type":"stream","name":"stdout","text":"incorrect format in: row=По словам очевидцев пешехо\n file=21013_text\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 745/745 [00:02<00:00, 297.30it/s]\n"}],"execution_count":326},{"cell_type":"code","source":"#!g1.1\ndef in_range(range1, range2):\n    # range1 in range2\n    if range1[0] is None: return True\n    if range2[0] is None: return False\n    return int(range2[0]) <= int(range1[0]) and int(range2[1]) >= int(range1[1])\n\ndef is_nested_anns(ent1: Ann, ent2: Ann):\n    # ent 1 in ent 2\n    res = True\n    ent1_range1 = (ent1.start1, ent1.end1)\n    ent1_range2 = (ent1.start2, ent1.end2)\n    ent2_range1 = (ent2.start1, ent2.end1)\n    ent2_range2 = (ent2.start2, ent2.end2)\n    #print(f'{ent1_range1=} {ent1_range2=} {ent1_range2=} {ent2_range2=}')\n    res = res and (in_range(ent1_range1, ent2_range1) or in_range(ent1_range1, ent2_range2))\n    res = res and (in_range(ent1_range2, ent2_range1) or in_range(ent1_range2, ent2_range2))\n    return res\n\n\ndef is_nested_anns2(ent1: Ann, ent2: Ann):\n    return is_nested_anns(ent1,ent2) or is_nested_anns(ent2, ent1)\n\ndef is_nested(rel: Rel):\n    return is_nested_anns(rel.arg1, rel.arg2) or is_nested_anns(rel.arg2, rel.arg1)","metadata":{"id":"h6WVK5qx1-EL","cellId":"2a1fb212-0507-4f22-a453-4aa5d73e56ab","trusted":true},"outputs":[],"execution_count":327},{"cell_type":"markdown","source":"![](https://i.imgur.com/tgDfc8i.png)             | ![](https://i.imgur.com/oWa5vWo.png)\n:-------------------------:|:-------------------------:\n","metadata":{"cellId":"95ec3a08-ff60-40da-a345-8cb8c139c29e","id":"ZQUnNVl22pRD"}},{"cell_type":"code","source":"#!g1.1\n%pip install transformers","metadata":{"outputId":"9ff56f9d-ff91-498d-8d38-0bcbc27555cd","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"UvEar7XL3O_u","scrolled":true,"cellId":"8f3082f8-bbfc-40ce-8e38-3ef6f998f18f"},"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (2.5.1)\nRequirement already satisfied: numpy in /kernel/lib/python3.7/site-packages (from transformers) (1.19.4)\nRequirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.12.31)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2021.7.6)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.96)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.50.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\nRequirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: requests in /kernel/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers) (0.10.0)\nRequirement already satisfied: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers) (1.15.49)\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers) (0.3.7)\nRequirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.7/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (0.15.2)\nRequirement already satisfied: urllib3<1.26,>=1.20 in /home/jupyter/.local/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (1.25.11)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /kernel/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (2.8.2)\nRequirement already satisfied: six>=1.5 in /kernel/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.31->boto3->transformers) (1.16.0)\nRequirement already satisfied: chardet<5,>=3.0.2 in /kernel/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\nRequirement already satisfied: idna<3,>=2.5 in /kernel/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\nRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\nYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\n"}],"execution_count":328},{"cell_type":"markdown","source":"# Dataset","metadata":{"cellId":"hbfwitjbqoiti9fghjjy8"}},{"cell_type":"code","source":"#!g1.1\nimport os\nimport torch\nimport time\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport numpy as np\nfrom tqdm.notebook import tqdm\nimport torchvision\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport random\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau","metadata":{"id":"niitsyy82pfO","cellId":"fe996418-4911-4f47-9bc5-29970268b416","trusted":true},"outputs":[],"execution_count":329},{"cell_type":"code","source":"#!g1.1\nfrom transformers import BertForSequenceClassification, BertTokenizer","metadata":{"id":"ExNYmaho3aFO","cellId":"cae0d712-a4a9-47f2-8505-788b718f8950","trusted":true},"outputs":[],"execution_count":330},{"cell_type":"code","source":"#!g1.1\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint('Using {} device'.format(device))","metadata":{"outputId":"3ef609a8-69a1-4fc1-868c-5573024aa98d","id":"EP9xO8an3Kyd","cellId":"8f8d67ac-4008-498e-b5fd-444672043c1b","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":"Using cuda device\n"}],"execution_count":331},{"cell_type":"code","source":"#!g1.1\ntokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased-sentence')","metadata":{"outputId":"119cabe3-2ffc-4fd7-9707-b3315dec26dc","id":"bj1_NVlF4SQ5","cellId":"f18b7438-46b2-45f8-ae45-db5ea42e4bf3","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["f77da0d2f01645e39f61678915e1e5dd","15582376f7984de884ebcd1f913fbe57","ffd5f1e21d8e456fa88f1ed81df1d988","d57085df67b64bc89f50e9e201ffd831","4dbb5dbc1e504307babd12634d29c81e","76fd931459754c148c320854fa91797c","58eed6a400664d74a790dd72255fd63b","c3153df30cdf480d8a045d1e079ec8eb","f7bdb939e91f4345b79ef35da1b4362b","47dbf5127c9647d585bc3dcf6a028851","2e92c8deed234326aa88b0b23ae16d44","56be7515ba554ac79d6a2e70e6d272d7","7be91583260c4c9e97827d65d150566b","cd4ef76a141046728258c305dd36315f"]}},"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1649718.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08f74e5a038d43a8a949185b6f8a5c43"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=112.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b79f6b033784b0fa09d8d07e6669a83"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=24.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6b35895255d411d968eb0c49909f256"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"}],"execution_count":332},{"cell_type":"code","source":"#!g1.1\nMAX_LENGTH = 100","metadata":{"id":"hZsLjKts8LDL","cellId":"34f918fb-625c-4e9c-a80c-353f55d96dab","trusted":true},"outputs":[],"execution_count":333},{"cell_type":"code","source":"#!g1.1\n# import nltk\n# nltk.download('punkt')\n# #!g1.1\n# sents = nltk.sent_tokenize(texts[0])\n# len(' '.join(sents))","metadata":{"cellId":"r9zuw8qveyos0zawzihxi","trusted":true},"outputs":[],"execution_count":334},{"cell_type":"code","source":"#!g1.1\nclass Binary_Tag:\n    def __getitem__(self, x):\n        if (x == 'None'): return 0\n        else: return 1\n\n# tags = list(set(e.tag for e in sum(relationships,[]))) + ['None'] # ids --> string tag\nreversed_tags = Binary_Tag() # string tag --> ids\nentity_tags = list(set(e.tag for e in sum(entities,[]))) \n\ndef tok(text1, text2):\n    # longest entity is 36 tokens long\n    res = tokenizer.encode_plus(text1, text2,\n                      max_length = MAX_LENGTH,\n                      pad_to_max_length = True,\n                      return_tensors = 'pt',\n                      )\n    return res['input_ids'][0], res['attention_mask'][0], res['token_type_ids'][0]\n    \nclass MyDataset(torch.utils.data.Dataset):\n    def __init__(self, folder):\n        texts, entities, relationships, filenames = read_files(folder)\n        \n        pre_dataset = []\n\n        for text_id in range(len(texts)):\n            relationships_nested = {(e.arg1, e.arg2):e for e in relationships[text_id] if is_nested(e)}\n            nes = []\n            for i in range(len(entities[text_id])):\n                # O(n^2) eeeeeeeeee\n                for j in range(i+1, len(entities[text_id])):\n                    if (is_nested_anns2(entities[text_id][i], entities[text_id][j])):\n                        nes.append((entities[text_id][i], entities[text_id][j]))\n            for e in nes:\n                if (e in relationships_nested):\n                    pre_dataset.append((*e, relationships_nested[e].tag, text_id))\n                elif ((e[1], e[0]) in relationships_nested):\n                    pre_dataset.append((e[1], e[0], relationships_nested[(e[1], e[0])].tag, text_id))\n                else:\n                    pre_dataset.append((*e, 'None', text_id))\n\n#         random.seed(2021)\n        data = []\n        for e1, e2, tag, text_id in tqdm(pre_dataset):\n            \n            data.append((reversed_tags[tag], entity_tags.index(e1.tag), entity_tags.index(e2.tag), tag, *tok(e1.text, e2.text)))\n        \n        self.data = data\n    \n    def __getitem__(self, index):\n        return self.data[index]\n    \n    def __len__(self):\n        return len(self.data)\n    ","metadata":{"id":"wBfCFhgd6dB5","cellId":"6b9fb08d-f9a8-4462-89f9-f460cc6b72ec","trusted":true},"outputs":[],"execution_count":335},{"cell_type":"code","source":"#!g1.1\ntrain_data = MyDataset('NEREL/NEREL-v1.0/train')\ntrain_dl = DataLoader(train_data, shuffle=True, batch_size=32)\n\ndev_data = MyDataset('NEREL/NEREL-v1.0/dev')\ndev_dl = DataLoader(dev_data, batch_size=32)","metadata":{"outputId":"691101df-e6f5-4892-bcf9-095da0682d2e","id":"rvd8pCDp9nP_","cellId":"d307436a-2010-470f-9776-af9604b914d0","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":297,"referenced_widgets":["a4cfe2484121444aa63a6f186dd1702d","09c1193eb65d49ddbe17782b10b2a28d","d235f966faa6422d957e4663f531f702","3cc0beef069e4487b4787dbc86cfdc17","c00fff84efb4422ebae3f0660b04b024","506d596cf5d14cbc9ae5cdbca0eed41a","2ab1804bc4cb4403a45a819d176cf1e8","66ab50997c66473ebec11e720ceb10eb","98fcbf82905b45d582497d16b4fc891d","e1f100f2b91d4f48b6fa15c32d4eaa90","bf0e06dea8d54891aa7850733224fe6a","b35e1699140440a48100850aaf7cf8d0","c4958973a07d4e20b1a7e44c015521fa","6fa03b923c3e49229ce47fa7a129fe83","ba77f76f2f8640d1a5079a8f385ac199","19b49586c4f448d5b455ad80607877a4"]}},"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=745.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf64b3e67ad74c41a25124ba995e8222"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"incorrect format in: row=По словам очевидцев пешехо\n file=21013_text\n\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11175.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"989c7c9b460b4248af8b97906a005010"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=93.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d9d7a61575f401c89971d31fb25392f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1301.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0c5b2abb163476dbfec8698e460f7ff"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"}],"execution_count":336},{"cell_type":"code","source":"#!g1.1\nnext(iter(dev_dl))[1]","metadata":{"outputId":"d92ebfcb-b8aa-44db-e4af-9500b36b7dd6","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"xxzNJH5Y_xtP","scrolled":true,"cellId":"43abbd3c-3534-4227-9254-9faca815eb87"},"outputs":[],"execution_count":317},{"cell_type":"code","source":"#!g1.1\nnext(iter(dev_dl))[1].size()","metadata":{"outputId":"c29a7530-2400-499a-8736-79bcd56c8976","id":"8bymmZZDFlkk","cellId":"0d8e26a9-85e9-48e9-8f47-8cc686180488","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":318},{"cell_type":"markdown","source":"# Training","metadata":{"cellId":"wlzglxz3q9f5e78w96x64x"}},{"cell_type":"code","source":"#!g1.1\nfrom transformers import BertTokenizer, BertModel\nclass MyModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = BertModel.from_pretrained(\n            \"DeepPavlov/rubert-base-cased-sentence\", # Use the 12-layer BERT model, with an uncased vocab.\n            output_attentions = False, # Whether the model returns attentions weights.\n            output_hidden_states = False, # Whether the model returns all hidden-states.\n            max_length = MAX_LENGTH\n            )\n        self.dropout = nn.Dropout(0.1)\n        self.emb = nn.Embedding(29, 10)\n        self.fc = nn.Sequential(\n            nn.Linear(768 + 10*2, 200),\n            nn.LeakyReLU(True),\n            nn.Linear(200, 200),\n            nn.LeakyReLU(True),\n            nn.Linear(200, 2)\n            )\n        \n    def forward(self, ent1, ent2, input_ids, attention_mask, token_type_ids, labels):\n        ent1 = self.emb(ent1)\n        ent2 = self.emb(ent2)\n        out = self.bert(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask)[1]\n        out = self.dropout(out)\n        out = torch.cat((out, ent1, ent2), dim=1)\n        out = self.fc(out)\n        criterion = nn.CrossEntropyLoss()\n        loss = criterion(out.view(-1, 2), labels.view(-1))\n        return loss, out\n    \n        # requires reconfiguration of hyper parameters\n#         criterion = nn.BCEWithLogitsLoss()\n#         out = self.fc(out).view(-1)\n#         loss = criterion(out, labels)\n#         return loss, torch.stack((-torch.sigmoid(out), torch.sigmoid(out)), dim = 1)","metadata":{"outputId":"58a26445-7e04-435f-d82c-70e9c23df45f","id":"caH7vsRBBfSu","cellId":"15fd00fb-66b7-47e1-99fc-fc58fc4534d0","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":337},{"cell_type":"code","source":"#!g1.1\nmodel = MyModel()\nmodel.to(device)","metadata":{"outputId":"684fa836-b717-45a4-bc1a-07bd997020f5","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"APMLLy0fDkKm","scrolled":true,"cellId":"10d7220b-ce5a-46e5-af1c-e320a53fa187"},"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=642.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae3c111610d644af9e71f80283865676"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=711456784.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f53f899017b4867ad15f6527d373136"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"MyModel(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (emb): Embedding(29, 10)\n  (fc): Sequential(\n    (0): Linear(in_features=788, out_features=200, bias=True)\n    (1): LeakyReLU(negative_slope=True)\n    (2): Linear(in_features=200, out_features=200, bias=True)\n    (3): LeakyReLU(negative_slope=True)\n    (4): Linear(in_features=200, out_features=2, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":338},{"cell_type":"code","source":"#!g1.1\ndef calculate_accuracy(y_pred, y):\n    return sum(torch.argmax(y_pred, axis = 1) == y)*1.0/len(y)\n\ndef train():\n    model.train()\n    running_loss = 0\n    epoch_accuracy = 0\n\n    pbar = tqdm(enumerate(train_dl), total = len(train_dl))\n    for i, (labels, tag1, tag2, true_tag, input_ids, attention_mask, token_type_ids) in pbar:\n        \n        labels = labels.to(device)\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        token_type_ids = token_type_ids.to(device)\n        tag1 = tag1.to(device)\n        tag2 = tag2.to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(tag1, tag2,\n                    input_ids, \n                    token_type_ids=token_type_ids,\n                    attention_mask=attention_mask, \n                    labels=labels)\n        \n        loss = outputs[0]\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n        epoch_accuracy += calculate_accuracy(outputs[1], labels).item()\n        running_loss += loss.item()\n        pbar.set_description(f'training: running_loss = {running_loss/(i+1.0):.4f} accuracy = {epoch_accuracy/(i+1.0):.4f},')\n    \n    scheduler.step(running_loss/(i+1))\n    print(f'train loss= {running_loss/(i+1):.4f} \\n train accuracy = {epoch_accuracy/(i+1):.4f},')\n\n    \nfrom sklearn.metrics import f1_score\ndef test():\n    with torch.no_grad():\n        model.eval()\n        running_loss = 0\n        epoch_accuracy = 0\n\n#         dev_dl = DataLoader( MyDataset('NEREL/NEREL-v1.0/train'), batch_size = 32)\n\n        pbar = tqdm(enumerate(dev_dl), total = len(dev_dl))\n\n        y_true = []\n        y_pred = []\n\n        for i, (labels, tag1, tag2, true_tag, input_ids, attention_mask, token_type_ids) in pbar:\n            labels = labels.to(device)\n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)\n            token_type_ids = token_type_ids.to(device)\n            tag1 = tag1.to(device)\n            tag2 = tag2.to(device)\n\n            outputs = model(tag1, tag2,\n                        input_ids, \n                        token_type_ids=token_type_ids,\n                        attention_mask=attention_mask, \n                        labels=labels)\n\n            loss = outputs[0]\n#             calculate_accuracy(outputs[1], labels)\n            y_true += [e.item() for e in labels]\n            y_pred += [e.item() for e in torch.argmax(outputs[1], axis = 1)]\n            \n            running_loss += loss.item()\n            epoch_accuracy += calculate_accuracy(outputs[1], labels).item()\n            # pbar.set_description(f'testing: running_loss = {running_loss/(i+1):.4f} accuracy = {epoch_accuracy/(i+1):.4f},')\n#     print(y_true, y_pred)\n    print(f'test loss= {running_loss/(i+1):.4f} \\n test accuracy = {epoch_accuracy/(i+1):.4f}, F1 = {f1_score(y_true, y_pred)}')","metadata":{"id":"9jmrqyEk_MTw","cellId":"d470c70e-ba8e-44f1-91d0-65c80334cbda","trusted":true},"outputs":[],"execution_count":339},{"cell_type":"code","source":"#!g1.1\noptimizer = torch.optim.AdamW(model.parameters(),\n                  lr = 5e-5, # args.learning_rate \n                  eps = 5e-8#1e-8 # args.adam_epsilon \n                )\nscheduler = ReduceLROnPlateau(optimizer, patience = 3, cooldown = 1, factor = 0.5)","metadata":{"id":"ggQK1n44_3E_","cellId":"6075ac4b-e8b4-45f5-9054-cf98dbd8964b","trusted":true},"outputs":[],"execution_count":340},{"cell_type":"code","source":"#!g1.1\nseed_val = 2021\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\nfor epoch in range(1, 21):\n    print(f'epoch = {epoch}')\n    print('lr=', optimizer.param_groups[0]['lr'])\n    train()\n    test()","metadata":{"outputId":"0ece41b4-a99d-4cbd-caff-7d1dbaa4c998","id":"k-BXDd2F-gOv","cellId":"596d3a26-d2df-4534-8083-05b39a785275","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":487,"referenced_widgets":["b60e883030494014ad492832403b33dd","5fc641cfc31d4b55accf2b2e4d9174ed","84b6979101ac48c487a026a1ac83f08c","a310f204604d4dbf8a88a45900d0a9c7","744627484db14fe68e41a9f7b0db3a91","1d80c7709b284caf9d2c5fc8dd8db5f8","5cedf898058e4a969a188e9b4a8b5093","1d28a69fd87c4549bd491c270c3b2335","ca264fe88e414dfd99c96b811722f296","29d4d96d29e044808d88ba19e63f81d3","9a9b5effe3c048069641829df3495a1e","2dd5e1489bd847b29b4148c68352e37a","7364869ba6d94b80ac309d59a47362d1"]}},"outputs":[{"output_type":"stream","name":"stdout","text":"epoch = 1\nlr= 5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f4e70c8af434287909c2fdafd19c912"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.3389 \n train accuracy = 0.8526,\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9944548c0d654006a47b150c4fd19f1c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntest loss= 0.3258 \n test accuracy = 0.8673, F1 = 0.830558276199804\nepoch = 2\nlr= 5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"874dc03d515d4c73abe392288fa0ae81"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.2125 \n train accuracy = 0.9239,\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c958ca83e084fb0b89b88b247358d5e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntest loss= 0.3195 \n test accuracy = 0.8857, F1 = 0.8369565217391305\nepoch = 3\nlr= 5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58f3ee87f32e4c3d98a35c2a04c4be24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"645363b4980043669393c0e1d7b77a31"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.1780 \n train accuracy = 0.9414,\n\ntest loss= 0.3062 \n test accuracy = 0.8921, F1 = 0.8613569321533923\nepoch = 4\nlr= 5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd92bc7766374dfa985b75c421413abb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da2af804f9194d608f36913c915eb9fe"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.1524 \n train accuracy = 0.9523,\n\ntest loss= 0.3934 \n test accuracy = 0.8929, F1 = 0.8594377510040161\nepoch = 5\nlr= 5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a64922ad4ed746eab5e9040e3712b4a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"732485234547416d9d32e1747e01a56b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.1342 \n train accuracy = 0.9578,\n\ntest loss= 0.3497 \n test accuracy = 0.8864, F1 = 0.8520357497517378\nepoch = 6\nlr= 5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12fbcbe77a2348a781b23e106d4d299c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fec0853dbe04916b5936edd5f0097df"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.1183 \n train accuracy = 0.9659,\n\ntest loss= 0.3863 \n test accuracy = 0.8925, F1 = 0.8585757271815446\nepoch = 7\nlr= 5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adc4adafd86846a8ae63ff7186caa7e3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.1145 \n train accuracy = 0.9677,\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25f82af056884b9a930c58a0edd4432a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntest loss= 0.3978 \n test accuracy = 0.8883, F1 = 0.8548707753479126\nepoch = 8\nlr= 5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a636aaa8b6d424ba634819842f75766"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac7b02c84bf348fabe51cb5b9c67ec98"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.1008 \n train accuracy = 0.9709,\n\ntest loss= 0.5305 \n test accuracy = 0.8830, F1 = 0.8459214501510574\nepoch = 9\nlr= 5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d3d8a16b664413b94b724fe18b208ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b080069ba2894a59bef4db8039638b16"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.0940 \n train accuracy = 0.9739,\n\ntest loss= 0.4150 \n test accuracy = 0.8856, F1 = 0.8526211671612264\nepoch = 10\nlr= 5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6611869fd2fa414280e82c1e0f07a682"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc35724088224de69dc7ec7e06cfbc43"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.0961 \n train accuracy = 0.9754,\n\ntest loss= 0.4759 \n test accuracy = 0.8906, F1 = 0.8496319663512092\nepoch = 11\nlr= 5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4c447093cd14f5f94d0973ea77ef567"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.0942 \n train accuracy = 0.9751,\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26decbf5784f4514a7bff199770c076c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntest loss= 0.5170 \n test accuracy = 0.8822, F1 = 0.851063829787234\nepoch = 12\nlr= 5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c081d31b0fbf45f1a9a70723835be3fc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.1053 \n train accuracy = 0.9702,\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe85c4fefb92440b89d9ab8c310831de"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntest loss= 0.3757 \n test accuracy = 0.8833, F1 = 0.8445807770961146\nepoch = 13\nlr= 5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b8eba447c6d429fac7d4bcbc7abf971"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.1063 \n train accuracy = 0.9721,\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1bc4aa23cf44ca3bf3e94d8534ad90f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntest loss= 0.5328 \n test accuracy = 0.8525, F1 = 0.8235294117647058\nepoch = 14\nlr= 2.5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02fa5bec96de4bbc8b646ccd75d64fea"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.0745 \n train accuracy = 0.9808,\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f676aa5ad0c4dd3ac113c6dae57a8b9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntest loss= 0.4270 \n test accuracy = 0.8864, F1 = 0.8511066398390341\nepoch = 15\nlr= 2.5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cbdcf3755324664bb9a0ca6c4397284"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1c82699705a4fc698cd447f2dd2a1de"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.0542 \n train accuracy = 0.9856,\n\ntest loss= 0.4999 \n test accuracy = 0.8952, F1 = 0.8623115577889447\nepoch = 16\nlr= 2.5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c4f89c47ad14e9e82ba4cfcb7ac304f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.0504 \n train accuracy = 0.9860,\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07166e3b46f14d29b882caa68bc24578"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntest loss= 0.5096 \n test accuracy = 0.9017, F1 = 0.8668730650154799\nepoch = 17\nlr= 2.5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7da653604c6b431397b6f3ff823abaf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"980c8013544c48b68e64380e42d6bca0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.0499 \n train accuracy = 0.9851,\n\ntest loss= 0.5623 \n test accuracy = 0.8925, F1 = 0.8520461699895069\nepoch = 18\nlr= 2.5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1fe150968844d4691eee19dda01a213"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28144708828e434b9554832b58be1588"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.0598 \n train accuracy = 0.9855,\n\ntest loss= 0.5264 \n test accuracy = 0.8895, F1 = 0.8542713567839196\nepoch = 19\nlr= 2.5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df0d07e62a4948f0a88f60816a02fd52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48e49915f4d14ece851778cba5cf19ef"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.0448 \n train accuracy = 0.9883,\n\ntest loss= 0.5353 \n test accuracy = 0.8925, F1 = 0.8526645768025078\nepoch = 20\nlr= 2.5e-05\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=350.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf65da3e080a4b8a961e3c6a00929134"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntrain loss= 0.0428 \n train accuracy = 0.9888,\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4890dd570e8247258283f4060e06118b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\ntest loss= 0.4815 \n test accuracy = 0.8917, F1 = 0.8599801390268121\n"}],"execution_count":341},{"cell_type":"code","source":"#!g1.1\ntorch.save(model.state_dict(), 'models/Set2_BERT_Binary_tags_model2')","metadata":{"id":"EsPbh2mbK9lo","cellId":"f6afc164-beb3-44a6-8c30-394056f63d42","trusted":true},"outputs":[],"execution_count":324},{"cell_type":"code","source":"#!g1.1\nwith torch.no_grad():\n    model.eval()\n    running_loss = 0\n    epoch_accuracy = 0\n\n    dev_dl = DataLoader( MyDataset('NEREL/NEREL-v1.0/dev'), batch_size = 1)\n\n    pbar = tqdm(enumerate(dev_dl), total = len(dev_dl))\n\n    y_true = []\n    y_pred = []\n    tags = []\n\n    for i, (labels, tag1, tag2, true_tag, input_ids, attention_mask, token_type_ids) in pbar:\n        labels = labels.to(device)\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        token_type_ids = token_type_ids.to(device)\n        tag1 = tag1.to(device)\n        tag2 = tag2.to(device)\n\n        outputs = model(tag1, tag2,\n                        input_ids, \n                        token_type_ids=token_type_ids,\n                        attention_mask=attention_mask, \n                        labels=labels)\n\n        loss = outputs[0]\n#             calculate_accuracy(outputs[1], labels)\n        y_true += [e.item() for e in labels]\n        y_pred += [e.item() for e in torch.argmax(outputs[1], axis = 1)]\n        tags += [(tag1, tag2)]\n        \n        running_loss += loss.item()\n        epoch_accuracy += calculate_accuracy(outputs[1], labels).item()\n        if (torch.argmax(outputs[1], axis = 1) != labels):\n            print('expected:', labels.detach().cpu().item())\n            print('found:', torch.argmax(outputs[1], axis = 1).detach().cpu().item(), '(', outputs[1].detach().cpu().numpy() ,')')\n            print(f'{entity_tags[tag1[0]]} ---> {entity_tags[tag2[0]]} : {true_tag[0]}')\n            print(tokenizer.decode(input_ids[0].detach().cpu().numpy()).replace(r'[PAD]', ''))\n            print()\n            \nprint(f'test loss= {running_loss/(i+1):.4f} \\n test accuracy = {epoch_accuracy/(i+1):.4f}, F1 = {f1_score(y_true, y_pred)}')","metadata":{"scrolled":true,"cellId":"lhqv82upz1hr2k8wmfe5zn","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nfrom collections import Counter\nl = []\nfor true, pred, t in zip(y_true, y_pred, tags):\n    if (true != pred):\n        l.append((t[0][0], t[1][0]))\nCounter(l).most_common()","metadata":{"cellId":"lijv8ns6u79uftb46nk7wa","trusted":true},"outputs":[],"execution_count":206},{"cell_type":"code","source":"#!g1.1\ntags[0][1][0]","metadata":{"cellId":"thbvgnl822gvh096517voh","trusted":true},"outputs":[],"execution_count":204}]}